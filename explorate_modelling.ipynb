{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, fclusterdata, linkage\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import scipy.spatial as spatial\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import timedelta\n",
    "import stablerank_custom.srank as sr\n",
    "from scipy.sparse import csgraph\n",
    "inf = float(\"inf\")\n",
    "nan = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "deso_url = 'https://geodata.scb.se/geoserver/stat/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=stat%3ADeSO.2018&outputFormat=Geopackage&format_options=charset:UTF-8'\n",
    "deso = gpd.read_file(deso_url)\n",
    "deso[\"x\"] = deso.centroid.map(lambda p: p.x)\n",
    "deso[\"y\"] = deso.centroid.map(lambda p: p.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('output/enriched_data.pkl')\n",
    "#df = df.merge(deso[['x', 'y', 'deso']], left_on = 'deso', right_on = 'deso')\n",
    "df['TEAM_MAGDA'] = df[['S', 'V', 'C', 'MP']].sum(axis = 1)\n",
    "df['TEAM_UFFE'] = df[['M', 'SD', 'L', 'KD']].sum(axis = 1)\n",
    "for p in ['S', 'SD', 'M', 'V', 'C', 'KD', 'MP', 'L']:\n",
    "    df[p + '_'] = df[p] - df[p].mean()\n",
    "df['STÖRSTA_PARTI_ADJUSTED'] = df[['S_', 'SD_', 'M_', 'V_', 'C_', 'KD_', 'MP_', 'L_']].idxmax(axis=1)\n",
    "df['STÖRSTA_BLOCK'] = df[['TEAM_MAGDA', 'TEAM_UFFE']].idxmax(axis=1)\n",
    "df['ORTSTYP'] = df.deso.str[4]\n",
    "scaler = StandardScaler()\n",
    "non_model_variables = ['deso',\n",
    "                        'kommun', 'kommunnamn', 'lan',\n",
    "                        'index_right', 'Lkfv', 'Vdnamn',\n",
    "                        'Distriktkod', 'Distriktnamn', 'ORTSTYP',\n",
    "                        'S', 'SD', 'M', 'V', 'C', 'KD', 'MP', 'L',\n",
    "                        'S_', 'SD_', 'M_', 'V_', 'C_', 'KD_', 'MP_', 'L_',\n",
    "                        'STÖRSTA_PARTI', 'STÖRSTA_PARTI_ADJUSTED',\n",
    "                        'TEAM_MAGDA', 'TEAM_UFFE']\n",
    "#non_model_variables = ['deso',\n",
    "#                        'kommun', 'lannamn', 'lan',\n",
    "#                        'index_right', 'Lkfv', 'Vdnamn',\n",
    "#                        'Distriktkod', 'Distriktnamn', 'ORTSTYP',\n",
    "#                        'S', 'SD', 'M', 'V', 'C', 'KD', 'MP', 'L',\n",
    "#                        'S_', 'SD_', 'M_', 'V_', 'C_', 'KD_', 'MP_', 'L_',\n",
    "#                        'STÖRSTA_PARTI', 'STÖRSTA_PARTI_ADJUSTED',\n",
    "#                        'TEAM_MAGDA', 'TEAM_UFFE']\n",
    "y = df['STÖRSTA_BLOCK']\n",
    "#df.set_index(['STÖRSTA_BLOCK', 'kommunnamn'], inplace = True)\n",
    "df.set_index(['STÖRSTA_BLOCK', 'lannamn'], inplace = True)\n",
    "X = df.drop(non_model_variables, axis = 1)\n",
    "X = pd.DataFrame(data = scaler.fit_transform(X), index = X.index, columns = X.columns)\n",
    "#X['x'] = deso['x'].values\n",
    "#X['y'] = deso['y'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting SVM for reference model\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [0.5, 0.6, 0.7, 0.8, 0.9, 0.99],\n",
    "    \"svc__C\": np.linspace(0.1,10,20),\n",
    "    \"svc__kernel\": ['rbf',],\n",
    "    \"svc__gamma\": ['auto'],\n",
    "}\n",
    "svc = SVC()\n",
    "pca = PCA()\n",
    "pipe = Pipeline([('pca', pca), ('svc',svc)])\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2, verbose = 1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "y_hat = search.predict(X_test)\n",
    "counter = 0\n",
    "for i,j in zip(y_test.values, y_hat):\n",
    "    if i == j:\n",
    "        counter += 1\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "print(counter/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_methods = ['single', 'average', 'complete', 'ward']\n",
    "distance = 'cityblock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the data into distance objects\n",
    "train_dist = [sr.Distance(spatial.distance.pdist(X_train.loc[X_train.index == i], distance)) for i in X_train.index.unique()]\n",
    "test_dist = [sr.Distance(spatial.distance.pdist(X_test.loc[X_test.index == i], distance)) for i in X_test.index.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into H0 stable ranks\n",
    "h0sr_train = {}\n",
    "h0sr_test = {}\n",
    "for cm in clustering_methods:\n",
    "    h0sr_train[cm] = [d.get_h0sr(clustering_method=cm) for d in train_dist]\n",
    "    h0sr_test[cm] = [d.get_h0sr(clustering_method=cm) for d in test_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into bar_codes and stable ranks\n",
    "bc_train = [d.get_bc(maxdim=1) for d in  train_dist]\n",
    "bc_test = [d.get_bc(maxdim=1) for d in  test_dist]\n",
    "h1sr_train = [sr.bc_to_sr(bar_code, degree=\"H1\") for bar_code in bc_train]\n",
    "h1sr_test = [sr.bc_to_sr(bar_code, degree=\"H1\") for bar_code in bc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0sr_train = {}\n",
    "h0_kernel_train ={}\n",
    "h1sr_train = []\n",
    "for cm in clustering_methods:\n",
    "    h0sr_train[cm] = []\n",
    "    for i in X_train.index.unique():\n",
    "        X_ = X_train.loc[X_train.index == i]\n",
    "        indicator = False\n",
    "        j = 1\n",
    "        while indicator == False:\n",
    "            knn_graph = kneighbors_graph(X_, j, include_self = False, metric = metric)\n",
    "            n_components, labels = csgraph.connected_components(knn_graph)\n",
    "            if (n_components == 1):\n",
    "                indicator = True\n",
    "            else:\n",
    "                j += 1\n",
    "        model = AgglomerativeClustering(n_clusters=len(X_), connectivity = knn_graph, compute_full_tree = True, linkage = cm, affinity = 'euclidean', compute_distances = True)\n",
    "        model.fit(X_[['x', 'y']])\n",
    "        Z = np.transpose(np.array([model.children_[:,0], model.children_[:,1], model.distances_]))\n",
    "        #print('Computing h0', cm, i, j, len(X_))\n",
    "        h0sr = sr._linkage_to_stable_rank(Z, contour = sr.standard_contour(), w_p = inf, w_q = 1, reduced = True)\n",
    "        h0sr_train[cm].append([h0sr, i[0]])\n",
    "        # Need to encode the knn connectivity into d_\n",
    "        knn_array = knn_graph.toarray()\n",
    "        np.fill_diagonal(knn_array, 1)\n",
    "        distance_full = spatial.distance.pdist(X_[['x', 'y']], \"euclidean\")\n",
    "        distance_ref = np.max(distance_full)\n",
    "        d_ = spatial.distance.squareform(distance_full)\n",
    "        d_[np.where(knn_array == 0)] = distance_ref\n",
    "        \n",
    "        bc = sr._d_to_bc(d_, maxdim=1, thresh=inf, coeff=2, reduced=True)\n",
    "        if len(h1sr_train) < len(X_train.index.unique()):\n",
    "            #print('Computing h1')\n",
    "            h1sr = sr.bc_to_sr(bc, degree=\"H1\")\n",
    "            h1sr_train.append([h1sr, i[0]])\n",
    "        # get bc (how? just send distance matrix?)\n",
    "        # get h1sr from bc\n",
    "    h0_kernel_train[cm] = np.asarray([[f[0].dot(g[0]) for g in h0sr_train[cm]] for f in h0sr_train[cm]])\n",
    "h1_kernel_train = np.asarray([[f[0].dot(g[0]) for g in h1sr_train] for f in h1sr_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0sr_test = {}\n",
    "h0_kernel_test ={}\n",
    "h1sr_test = []\n",
    "for cm in clustering_methods:\n",
    "    h0sr_test[cm] = []\n",
    "    for i in X_test.index.unique():\n",
    "        X_ = X_test.loc[X_test.index == i]\n",
    "        indicator = False\n",
    "        j = 1\n",
    "        while indicator == False:\n",
    "            knn_graph = kneighbors_graph(X_, j, include_self = False, metric = metric)\n",
    "            n_components, labels = csgraph.connected_components(knn_graph)\n",
    "            if (n_components == 1):\n",
    "                indicator = True\n",
    "            else:\n",
    "                j += 1\n",
    "        model = AgglomerativeClustering(n_clusters=len(X_), connectivity = knn_graph, compute_full_tree = True, linkage = cm, affinity = 'euclidean', compute_distances = True)\n",
    "        model.fit(X_[['x', 'y']])\n",
    "        Z = np.transpose(np.array([model.children_[:,0], model.children_[:,1], model.distances_]))\n",
    "        #print('Computing h0', cm, i, j, len(X_))\n",
    "        h0sr = sr._linkage_to_stable_rank(Z, contour = sr.standard_contour(), w_p = inf, w_q = 1, reduced = True)\n",
    "        h0sr_test[cm].append([h0sr, i[0]])\n",
    "        # get bc (how? just send distance matrix?)\n",
    "        # get h1sr from bc\n",
    "        # Need to encode the knn connectivity into d_\n",
    "        knn_array = knn_graph.toarray()\n",
    "        np.fill_diagonal(knn_array, 1)\n",
    "        distance_full = spatial.distance.pdist(X_[['x', 'y']], \"euclidean\")\n",
    "        distance_ref = np.max(distance_full)\n",
    "        d_ = spatial.distance.squareform(distance_full)\n",
    "        d_[np.where(knn_array == 0)] = distance_ref\n",
    "        \n",
    "        bc = sr._d_to_bc(d_, maxdim=1, thresh=inf, coeff=2, reduced=True)\n",
    "        if len(h1sr_test) < len(X_test.index.unique()):\n",
    "            #print('Computing h1')\n",
    "            h1sr = sr.bc_to_sr(bc, degree=\"H1\")\n",
    "            h1sr_test.append([h1sr, i[0]])\n",
    "    h0_kernel_test[cm] = np.asarray([[f[0].dot(g[0]) for g in h0sr_train[cm]] for f in h0sr_test[cm]])\n",
    "h1_kernel_test = np.asarray([[f[0].dot(g[0]) for g in h1sr_train] for f in h1sr_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_kernel_train ={}\n",
    "h0_kernel_test ={}\n",
    "start = timer()    \n",
    "for cm in clustering_methods:\n",
    "    h0_kernel_train[cm] = np.asarray([[f.dot(g) for g in h0sr_train[cm]] for f in h0sr_train[cm]])\n",
    "    h0_kernel_test[cm] = np.asarray([[f.dot(g) for g in h0sr_train[cm]] for f in h0sr_test[cm]])\n",
    "    \n",
    "h1_kernel_train = np.asarray([[f.dot(g) for g in h1sr_train] for f in h1sr_train])\n",
    "h1_kernel_test = np.asarray([[f.dot(g) for g in h1sr_train] for f in h1sr_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "for i,f in zip(X_train.index.unique(), h0sr_train[\"single\"]):\n",
    "    i = i[0]\n",
    "    if i == 'TEAM_UFFE':\n",
    "        color = 'blue'\n",
    "    elif i == 'TEAM_MAGDA':\n",
    "        color = 'red'\n",
    "    f.plot(color=color, linewidth=1)\n",
    "    plt.xlabel('Distance threshold', fontsize = 24)\n",
    "    plt.ylabel('Rank of homology', fontsize = 24)\n",
    "    plt.savefig('images/h0_sr_single_' + distance + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "for i,f in zip(X_train.index.unique(), h0sr_train[\"average\"]):\n",
    "    i = i[0]\n",
    "    if i == 'TEAM_UFFE':\n",
    "        color = 'blue'\n",
    "    elif i == 'TEAM_MAGDA':\n",
    "        color = 'red'\n",
    "    f.plot(color=color, linewidth=1)\n",
    "    plt.xlabel('Distance threshold', fontsize = 24)\n",
    "    plt.ylabel('Rank of homology', fontsize = 24)\n",
    "    plt.savefig('images/h0_sr_average_' + distance + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "for i,f in zip(X_train.index.unique(), h0sr_train[\"complete\"]):\n",
    "    i = i[0]\n",
    "    if i == 'TEAM_UFFE':\n",
    "        color = 'blue'\n",
    "    elif i == 'TEAM_MAGDA':\n",
    "        color = 'red'\n",
    "    f.plot(color=color, linewidth=1)\n",
    "    plt.xlabel('Distance threshold', fontsize = 24)\n",
    "    plt.ylabel('Rank of homology', fontsize = 24)\n",
    "    plt.savefig('images/h0_sr_complete_' + distance + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "for i,f in zip(X_train.index.unique(), h0sr_train[\"ward\"]):\n",
    "    i = i[0]\n",
    "    if i == 'TEAM_UFFE':\n",
    "        color = 'blue'\n",
    "    elif i == 'TEAM_MAGDA':\n",
    "        color = 'red'\n",
    "    f.plot(color=color, linewidth=1)\n",
    "    plt.xlabel('Distance threshold', fontsize = 24)\n",
    "    plt.ylabel('Rank of homology', fontsize = 24)\n",
    "    plt.savefig('images/h0_sr_ward_' + distance + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "for i,f in zip(X_train.index.unique(), h1sr_train):\n",
    "    i = i[0]\n",
    "    if i == 'TEAM_UFFE':\n",
    "        color = 'blue'\n",
    "    elif i == 'TEAM_MAGDA':\n",
    "        color = 'red'\n",
    "    f.plot(color=color, linewidth=1)\n",
    "    plt.xlabel('Distance threshold', fontsize = 24)\n",
    "    plt.ylabel('Rank of homology', fontsize = 24)\n",
    "    plt.savefig('images/h1_sr_' + distance + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "a_score = {}\n",
    "for cm in clustering_methods:\n",
    "    param_grid = {\n",
    "    \"C\": np.linspace(0.01,0.2,20),\n",
    "    }\n",
    "    svc = SVC(kernel='precomputed')\n",
    "    search = GridSearchCV(svc, param_grid, n_jobs=2, verbose = 1)\n",
    "    search.fit(h0_kernel_train[cm], X_train.index.unique().get_level_values(0))\n",
    "    #search.fit(h1_kernel_train, X_train.index.unique().get_level_values(0))\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    prediction[cm] = search.predict(h0_kernel_test[cm])\n",
    "    #prediction[cm] = search.predict(h1_kernel_test)\n",
    "    a_score[cm] = accuracy_score(X_test.index.unique().get_level_values(0), prediction[cm])\n",
    "    print(cm+\": \", a_score[cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "a_score = {}\n",
    "for cm in clustering_methods:\n",
    "    param_grid = {\n",
    "    \"C\": np.linspace(0.01,0.2,20),\n",
    "    }\n",
    "    svc = SVC(kernel='precomputed')\n",
    "    search = GridSearchCV(svc, param_grid, n_jobs=2, verbose = 1)\n",
    "    #search.fit(h0_kernel_train[cm], X_train.index.unique().get_level_values(0))\n",
    "    search.fit(h1_kernel_train, X_train.index.unique().get_level_values(0))\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    #prediction[cm] = search.predict(h0_kernel_test[cm])\n",
    "    prediction[cm] = search.predict(h1_kernel_test)\n",
    "    a_score[cm] = accuracy_score(X_test.index.unique().get_level_values(0), prediction[cm])\n",
    "    print(cm+\": \", a_score[cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_kernel_train = {}\n",
    "composed_kernel_test = {}\n",
    "for cm in clustering_methods:\n",
    "    composed_kernel_train[cm] = np.add(h0_kernel_train[cm], h1_kernel_train)\n",
    "    composed_kernel_test[cm] = np.add(h0_kernel_test[cm], h1_kernel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_kernel_train = {}\n",
    "composed_kernel_test = {}\n",
    "for cm in clustering_methods:\n",
    "    composed_kernel_train[cm] = np.max(np.array([h0_kernel_train[cm], h1_kernel_train]), axis = 0)\n",
    "    composed_kernel_test[cm] = np.max(np.array([h0_kernel_test[cm], h1_kernel_test]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_kernel_train = {}\n",
    "composed_kernel_test = {}\n",
    "for cm in clustering_methods:\n",
    "    composed_kernel_train[cm] = np.min(np.array([h0_kernel_train[cm], h1_kernel_train]), axis = 0)\n",
    "    composed_kernel_test[cm] = np.min(np.array([h0_kernel_test[cm], h1_kernel_test]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_kernel_train = {}\n",
    "composed_kernel_test = {}\n",
    "for cm in clustering_methods:\n",
    "    composed_kernel_train[cm] = np.linalg.norm(np.array([h0_kernel_train[cm], h1_kernel_train]), axis = 0, ord = 2)\n",
    "    composed_kernel_test[cm] = np.linalg.norm(np.array([h0_kernel_test[cm], h1_kernel_test]), axis = 0, ord = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "a_score = {}\n",
    "for cm in clustering_methods:\n",
    "    param_grid = {\n",
    "    \"C\": np.linspace(0.01,0.2,20),\n",
    "    }\n",
    "    svc = SVC(kernel='precomputed')\n",
    "    search = GridSearchCV(svc, param_grid, n_jobs=2, verbose = 1)\n",
    "    search.fit(composed_kernel_train[cm], X_train.index.unique().get_level_values(0))\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    #prediction[cm] = search.predict(h0_kernel_test[cm])\n",
    "    prediction[cm] = search.predict(composed_kernel_test[cm],)\n",
    "    a_score[cm] = accuracy_score(X_test.index.unique().get_level_values(0), prediction[cm])\n",
    "    print(cm+\": \", a_score[cm])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo SE Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
