{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stablerank_custom.srank as sr\n",
    "from ripser import ripser\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "inf=float(\"inf\")\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import scipy.spatial as spatial\n",
    "import scipy.stats as st\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle(c, r, s, error=0):\n",
    "    t = np.random.uniform(high=2 * np.pi, size=s)\n",
    "    y = np.sin(t) * r + c[1]\n",
    "    x = np.cos(t) * r + c[0]\n",
    "    sd = error * 0.635\n",
    "    pdf = st.norm(loc=[0, 0], scale=(sd, sd))\n",
    "    return pdf.rvs((s, 2)) + np.vstack([x, y]).transpose()\n",
    "\n",
    "def closed_path(vertices, s, error=0):\n",
    "    v = np.asarray(vertices)\n",
    "    number_v = len(v)\n",
    "    l1 = np.linalg.norm(v[1:, :] - v[:-1, :], axis=1)\n",
    "    _l = np.concatenate([l1, np.array([np.linalg.norm(v[0] - v[-1])])])\n",
    "    accum_l = np.asarray(list(it.accumulate(_l)))\n",
    "    t = np.random.uniform(high=accum_l[-1], size=s)\n",
    "    points = np.empty([0, 2])\n",
    "    for i in t:\n",
    "        index = np.searchsorted(accum_l, i)\n",
    "        coeff = (accum_l[index] - i) / (_l[index])\n",
    "        if index == number_v - 1:\n",
    "            points = np.vstack((points, (coeff * v[0] + (1 - coeff) * v[-1])))\n",
    "        else:\n",
    "            points = np.vstack((points, (coeff * v[index + 1] + (1 - coeff) * v[index])))\n",
    "    sd = error * 0.635\n",
    "    pdf = st.norm(loc=[0, 0], scale=(sd, sd))\n",
    "    return pdf.rvs((s, 2)) + points\n",
    "\n",
    "def uniform_noise(x_min, x_max, y_min, y_max, s):\n",
    "    x = (np.random.random(s) * (x_max - x_min)) + x_min\n",
    "    y = (np.random.random(s) * (y_max - y_min)) + y_min\n",
    "    return np.vstack((x, y)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "i = 0\n",
    "while i < 100:\n",
    "    c = circle([0,0], 1, 100, error=0.2)\n",
    "    data.append(c)\n",
    "    i += 1  \n",
    "i = 0\n",
    "while i < 100:\n",
    "    s = closed_path([[-0.9,-0.8],[0.8,-1],[0.8,0.7],[-0.7,1]], 100, error=0.2)\n",
    "    data.append(s)\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 57\n",
    "j= 156\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(data[i][:,0],data[i][:,1], color=\"red\")\n",
    "plt.scatter(data[j][:,0],data[j][:,1], color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,40))\n",
    "axes = fig.subplots(1, 3) \n",
    "ax_left = axes[0]\n",
    "ax_left.set_box_aspect(1)\n",
    "i = 0\n",
    "while i <100:\n",
    "    ax_left.scatter(data[i][:,0],data[i][:,1])\n",
    "    i += 1\n",
    "    \n",
    "ax_center = axes[1]\n",
    "ax_center.set_box_aspect(1)\n",
    "i = 100\n",
    "while i <200:\n",
    "    ax_center.scatter(data[i][:,0],data[i][:,1])\n",
    "    i += 1\n",
    "\n",
    "ax_right = axes[2]\n",
    "ax_right.set_box_aspect(1) \n",
    "i = 57\n",
    "j= 134\n",
    "ax_right.scatter(data[i][:,0],data[i][:,1], color=\"red\")\n",
    "ax_right.scatter(data[j][:,0],data[j][:,1], color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "i = 0\n",
    "while i < 100:\n",
    "    c = circle([0,0], 1, 100, error=0.2)\n",
    "    train.append(c)\n",
    "    i += 1\n",
    "i = 0\n",
    "while i < 100:\n",
    "    s = closed_path([[-0.9,-0.8],[0.8,-1],[0.8,0.7],[-0.7,1]], 100, error=0.2)\n",
    "    train.append(s)\n",
    "    i += 1  \n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d.flatten() for d in train]\n",
    "\n",
    "zeros = np.zeros((100,), dtype=int)\n",
    "ones= np.ones((100,), dtype=int)\n",
    "y = np.concatenate([zeros,ones])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "test = [d.flatten() for d in data]\n",
    "pred = clf.predict(test)\n",
    "a_score = accuracy_score(y, pred)\n",
    "print(a_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting H0 stable ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the data into distance objects\n",
    "data_dist = [sr.Distance(spatial.distance.pdist(fig, \"euclidean\")) for fig in data]\n",
    "train_dist = [sr.Distance(spatial.distance.pdist(fig, \"euclidean\")) for fig in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into H0 stable ranks\n",
    "clustering_methods = [\"single\", \"complete\", \"average\", \"ward\"]\n",
    "data_h0sr = {}\n",
    "train_h0sr = {}\n",
    "for cm in clustering_methods:\n",
    "    data_h0sr[cm] = [d.get_h0sr(clustering_method=cm) for d in data_dist]\n",
    "    train_h0sr[cm] = [d.get_h0sr(clustering_method=cm) for d in train_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_h0sr[cm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the signal our H0 homology sense produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h0sr[\"single\"]:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h0sr[\"complete\"]:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h0sr[\"average\"]:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h0sr[\"ward\"]:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us use SVM as a computer inteligance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_kernel_train ={ }\n",
    "h0_kernel_test ={ }\n",
    "start = timer()    \n",
    "for cm in clustering_methods:\n",
    "    h0_kernel_train[cm] = np.asarray([[f.dot(g) for g in train_h0sr[cm]] for f in train_h0sr[cm]])\n",
    "    h0_kernel_test[cm] = np.asarray([[f.dot(g) for g in train_h0sr[cm]] for f in data_h0sr[cm]])\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h0_kernel_train[cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h0_kernel_train['single'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "a_score = {}\n",
    "for cm in clustering_methods:\n",
    "    clf = svm.SVC(kernel='precomputed')\n",
    "    clf.fit(h0_kernel_train[cm], y)\n",
    "    prediction[cm] = clf.predict(h0_kernel_test[cm])\n",
    "    a_score[cm] = accuracy_score(y, prediction[cm])\n",
    "    print(cm+\": \", a_score[cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist[0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us extract bar codes and higher homology stable ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into bar_codes and stable ranks\n",
    "data_bc = [d.get_bc(maxdim=1) for d in  data_dist]\n",
    "\n",
    "data_h1sr = [sr.bc_to_sr(bar_code, degree=\"H1\") for bar_code in data_bc]\n",
    "\n",
    "train_bc = [d.get_bc(maxdim=1) for d in  train_dist]\n",
    "\n",
    "train_h1sr = [sr.bc_to_sr(bar_code, degree=\"H1\") for bar_code in train_bc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h1sr:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us use SVM as a computer inteligance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()    \n",
    "\n",
    "h1_kernel_train = np.asarray([[f.dot(g) for g in train_h1sr] for f in train_h1sr])\n",
    "h1_kernel_test = np.asarray([[f.dot(g) for g in train_h1sr] for f in data_h1sr])\n",
    "\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((100,), dtype=int)\n",
    "ones= np.ones((100,), dtype=int)\n",
    "y = np.concatenate([zeros,ones])\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='precomputed')\n",
    "clf.fit(h1_kernel_train, y)\n",
    "prediction = clf.predict(h1_kernel_test)\n",
    "a_score = accuracy_score(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The case of noisy to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "data_noise_level =[]\n",
    "i = 0\n",
    "while i < 100:\n",
    "    n = np.random.randint(10, 25)\n",
    "    data_noise_level.append(n)\n",
    "    c = circle([0,0], 1, 100-n, error=0.2)\n",
    "    noise = uniform_noise(-1.5, 1.5, -1.5, 1.5, n)\n",
    "    fig = np.concatenate([c,noise], axis=0)\n",
    "    data.append(fig)\n",
    "    i += 1  \n",
    "i = 0\n",
    "while i < 100:\n",
    "    n = np.random.randint(10, 25)\n",
    "    data_noise_level.append(n)\n",
    "    #t = closed_path([[-0.9,-0.8],[1.2,-0.2],[-0.2,1.2]], 100-n, error=0.2)\n",
    "    t = closed_path([[-0.9,-0.8],[0.8,-1],[0.8,0.7],[-0.7,1]], 100-n, error=0.2)\n",
    "    noise = uniform_noise(-1.5, 1.5, -1.5, 1.5, n)\n",
    "    fig = np.concatenate([t,noise], axis=0)\n",
    "    data.append(fig)\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,40))\n",
    "axes = fig.subplots(1, 3) \n",
    "ax_left = axes[0]\n",
    "ax_left.set_box_aspect(1)\n",
    "i = 0\n",
    "while i <100:\n",
    "    ax_left.scatter(data[i][:,0],data[i][:,1])\n",
    "    i += 1\n",
    "    \n",
    "ax_center = axes[1]\n",
    "ax_center.set_box_aspect(1)\n",
    "i = 100\n",
    "while i <200:\n",
    "    ax_center.scatter(data[i][:,0],data[i][:,1])\n",
    "    i += 1\n",
    "\n",
    "ax_right = axes[2]\n",
    "ax_right.set_box_aspect(1) \n",
    "i = 57\n",
    "j= 134\n",
    "ax_right.scatter(data[i][:,0],data[i][:,1], color=\"red\")\n",
    "ax_right.scatter(data[j][:,0],data[j][:,1], color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = []\n",
    "train_noise_level =[]\n",
    "i = 0\n",
    "while i < 100:\n",
    "    n = np.random.randint(10, 25)\n",
    "    train_noise_level.append(n)\n",
    "    c = circle([0,0], 1, 100-n, error=0.2)\n",
    "    noise = uniform_noise(-1.5, 1.5, -1.5, 1.5, n)\n",
    "    fig = np.concatenate([c,noise], axis=0)\n",
    "    train.append(fig)\n",
    "    i += 1  \n",
    "i = 0\n",
    "while i < 100:\n",
    "    n = np.random.randint(10, 25)\n",
    "    train_noise_level.append(n)\n",
    "    #t = closed_path([[-0.9,-0.8],[1.2,-0.2],[-0.2,1.2]], 100-n, error=0.2)\n",
    "    t = closed_path([[-0.9,-0.8],[0.8,-1],[0.8,0.7],[-0.7,1]], 100-n, error=0.2)\n",
    "    noise = uniform_noise(-1.5, 1.5, -1.5, 1.5, n)\n",
    "    fig = np.concatenate([t,noise], axis=0)\n",
    "    train.append(fig)\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 59\n",
    "print(data_noise_level[i])\n",
    "j= 156\n",
    "print(data_noise_level[j])\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(data[i][:,0],data[i][:,1], color=\"red\")\n",
    "plt.scatter(data[j][:,0],data[j][:,1], color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting H0 stable ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the data into distance objects\n",
    "data_dist = [sr.Distance(spatial.distance.pdist(fig, \"euclidean\")) for fig in data]\n",
    "train_dist = [sr.Distance(spatial.distance.pdist(fig, \"euclidean\")) for fig in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into H0 stable ranks\n",
    "clustering_methods = [\"single\", \"complete\", \"average\", \"ward\"]\n",
    "data_h0sr = {}\n",
    "train_h0sr = {}\n",
    "for cm in clustering_methods:\n",
    "    data_h0sr[cm] = [d.get_h0sr(clustering_method=cm) for d in data_dist]\n",
    "    train_h0sr[cm] = [d.get_h0sr(clustering_method=cm) for d in train_dist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the signal our H0 homology sense produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h0sr[\"complete\"]:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_kernel_train ={ }\n",
    "h0_kernel_test ={ }\n",
    "start = timer()    \n",
    "for cm in clustering_methods:\n",
    "    h0_kernel_train[cm] = np.asarray([[f.dot(g) for g in train_h0sr[cm]] for f in train_h0sr[cm]])\n",
    "    h0_kernel_test[cm] = np.asarray([[f.dot(g) for g in train_h0sr[cm]] for f in data_h0sr[cm]])\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "a_score = {}\n",
    "for cm in clustering_methods:\n",
    "    clf = svm.SVC(kernel='precomputed')\n",
    "    clf.fit(h0_kernel_train[cm], y)\n",
    "    prediction[cm] = clf.predict(h0_kernel_test[cm])\n",
    "    a_score[cm] = accuracy_score(y, prediction[cm])\n",
    "    print(cm+\": \", a_score[cm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us try with 1st homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into bar_codes and stable ranks\n",
    "data_bc = [d.get_bc(maxdim=1) for d in  data_dist]\n",
    "\n",
    "data_h1sr = [sr.bc_to_sr(bar_code, degree=\"H1\") for bar_code in data_bc]\n",
    "\n",
    "train_bc = [d.get_bc(maxdim=1) for d in  train_dist]\n",
    "\n",
    "train_h1sr = [sr.bc_to_sr(bar_code, degree=\"H1\") for bar_code in train_bc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h1sr:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()    \n",
    "\n",
    "h1_kernel_train = np.asarray([[f.dot(g) for g in train_h1sr] for f in train_h1sr])\n",
    "h1_kernel_test = np.asarray([[f.dot(g) for g in train_h1sr] for f in data_h1sr])\n",
    "\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((100,), dtype=int)\n",
    "ones= np.ones((100,), dtype=int)\n",
    "y = np.concatenate([zeros,ones])\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='precomputed')\n",
    "clf.fit(h1_kernel_train, y)\n",
    "prediction = clf.predict(h1_kernel_test)\n",
    "a_score = accuracy_score(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to lower deviation!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances = 7\n",
    "sample_size = 5\n",
    "n = 18\n",
    "s = sr.get_sample(number_instances, sample_size, n)\n",
    "print(s)\n",
    "print(s.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances = 200\n",
    "sample_size = 20\n",
    "\n",
    "c = data[3]\n",
    "\n",
    "d = spatial.distance.pdist(c, \"euclidean\")\n",
    "\n",
    "# getting a distance object\n",
    "c_dist = sr.Distance(d)\n",
    "\n",
    "\n",
    "s = sr.get_sample(number_instances, sample_size, c_dist.size())\n",
    "\n",
    "f = c_dist.get_h0sr(sample=s, clustering_method=\"complete\")\n",
    "\n",
    "b = c_dist.get_bc(sample=s)\n",
    "\n",
    "g = sr.bc_to_sr(b, degree=\"H1\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,20))\n",
    "axes = fig.subplots(1, 2) \n",
    "ax_left = axes[0]\n",
    "ax_left.set_box_aspect(1)\n",
    "f.plot(ax=ax_left)\n",
    "\n",
    "ax_right = axes[1]\n",
    "ax_right.set_box_aspect(1)\n",
    "g.plot(ax=ax_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances = 1000\n",
    "sample_size = 20\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "while i <20:\n",
    "    s = sr.get_sample(number_instances, sample_size, c_dist.size())\n",
    "    f = c_dist.get_h0sr(sample=s, clustering_method=\"complete\")\n",
    "    f.plot(linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances = 1000\n",
    "sample_size = 20\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "while i <20:\n",
    "    s = sr.get_sample(number_instances, sample_size, c_dist.size())\n",
    "    b = c_dist.get_bc(sample=s, maxdim=1)\n",
    "    f = sr.bc_to_sr(b, degree=\"H1\")\n",
    "    f.plot(linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrating averaged H0 stable ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into H0 stable ranks\n",
    "number_instances = 300\n",
    "sample_size = 20\n",
    "\n",
    "clustering_methods = [\"single\", \"complete\", \"average\", \"ward\"]\n",
    "data_h0sr = {}\n",
    "train_h0sr = {}\n",
    "start = timer()    \n",
    "for cm in clustering_methods:\n",
    "    data_h0sr[cm] = []\n",
    "    train_h0sr[cm] = []\n",
    "    for d in  data_dist:\n",
    "        s = sr.get_sample(number_instances, sample_size, d.size())\n",
    "        f = d.get_h0sr(sample=s, clustering_method=cm)\n",
    "        data_h0sr[cm].append(f)\n",
    "    for d in train_dist:\n",
    "        s = sr.get_sample(number_instances, sample_size,  d.size())\n",
    "        g = d.get_h0sr(sample=s, clustering_method=cm)\n",
    "        train_h0sr[cm].append(g)\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for f in data_h0sr[\"complete\"]:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.1)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_kernel_train ={ }\n",
    "h0_kernel_test ={ }\n",
    "start = timer()    \n",
    "for cm in clustering_methods:\n",
    "    h0_kernel_train[cm] = np.asarray([[f.dot(g) for g in train_h0sr[cm]] for f in train_h0sr[cm]])\n",
    "    h0_kernel_test[cm] = np.asarray([[f.dot(g) for g in train_h0sr[cm]] for f in data_h0sr[cm]])\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "a_score = {}\n",
    "for cm in clustering_methods:\n",
    "    clf = svm.SVC(kernel='precomputed')\n",
    "    clf.fit(h0_kernel_train[cm], y)\n",
    "    prediction[cm] = clf.predict(h0_kernel_test[cm])\n",
    "    a_score[cm] = accuracy_score(y, prediction[cm])\n",
    "    print(cm+\": \", a_score[cm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrating averaged H1 stable ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converitng the distance objects into H0 stable ranks\n",
    "number_instances = 400\n",
    "sample_size = 20\n",
    "\n",
    "data_h1sr = []\n",
    "train_h1sr = []\n",
    "start = timer()  \n",
    "for d in  data_dist:\n",
    "    s = sr.get_sample(number_instances, sample_size, d.size())\n",
    "    b = d.get_bc(sample=s, maxdim=1)\n",
    "    f = sr.bc_to_sr(b, degree=\"H1\")\n",
    "    data_h1sr.append(f)\n",
    "for d in train_dist:\n",
    "    s = sr.get_sample(number_instances, sample_size,  d.size())\n",
    "    b = d.get_bc(sample=s, maxdim=1)\n",
    "    f = sr.bc_to_sr(b, degree=\"H1\")\n",
    "    train_h1sr.append(f)\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,28))\n",
    "i = 0\n",
    "for f in data_h1sr:\n",
    "    if i <100:\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color = \"blue\"\n",
    "    f.plot(color=color, linewidth=0.5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()    \n",
    "h1_kernel_train = np.asarray([[f.dot(g) for g in train_h1sr] for f in train_h1sr])\n",
    "h1_kernel_test = np.asarray([[f.dot(g) for g in train_h1sr] for f in data_h1sr])\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='precomputed')\n",
    "clf.fit(h1_kernel_train, y)\n",
    "prediction = clf.predict(h1_kernel_test)\n",
    "a_score = accuracy_score(y, prediction)\n",
    "print(a_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_input = pd.read_csv(\"Data/breast-cancer-wisconsin.csv\", sep=\",\", header=None).to_numpy()\n",
    "input = np.empty(org_input.shape, dtype=\"double\")\n",
    "a = 0\n",
    "j = 0\n",
    "i = 0\n",
    "while i < len(org_input):\n",
    "    if org_input[i,5]!=\"?\":\n",
    "        j += 1\n",
    "        a += np.double(org_input[i,5])\n",
    "    i += 1\n",
    "avg = a/j     \n",
    "for i,x in np.ndenumerate(org_input):\n",
    "    if x==\"?\":\n",
    "        input[i]= avg\n",
    "    else:\n",
    "        input[i]= np.double(x)\n",
    "\n",
    "data = input[:,:9]\n",
    "classification = input[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of patients: \", len(classification))\n",
    "print(\"number of benign cases (class 2): \", len(np.where(classification==2)[0]))\n",
    "print(\"number of malignant cases (class 4): \", len(np.where(classification==4)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of data points: \", len(classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([i for i in range(len(classification)) if classification[i]==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = sr.Distance(spatial.distance.pdist(data, \"euclidean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisconsin_distances = distance.square_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(wisconsin_distances):\n",
    "    plt.hist(wisconsin_distances[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {}\n",
    "distributions[\"0_15\"] = sr.get_distribution(name=\"uniform\", interval=[0,15])\n",
    "distributions[\"5_20\"] = sr.get_distribution(name=\"uniform\", interval=[5,20])\n",
    "distributions[\"10_25\"] = sr.get_distribution(name=\"uniform\", interval=[10,25])\n",
    "distributions[\"10_30\"] = sr.get_distribution(name=\"uniform\", interval=[10,30])\n",
    "distributions[\"15_30\"] = sr.get_distribution(name=\"uniform\", interval=[15,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = {}\n",
    "for k in distributions.keys():\n",
    "    probabilities[k] = distributions[k](wisconsin_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_instances=300\n",
    "sample_size=30\n",
    "\n",
    "start = timer()    \n",
    "h0_sr = {}\n",
    "h1_sr = {}\n",
    "for k in  distributions.keys():\n",
    "    h0_sr[k] = []\n",
    "    h1_sr[k] = []\n",
    "    for patient in wisconsin_distances[0:1]:\n",
    "        p = distributions[k](patient)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance.get_h0sr(sample=s,clustering_method=\"complete\")\n",
    "        b = distance.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr[k].append(f)\n",
    "        h1_sr[k].append(g)\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in distributions.keys():\n",
    "    fig = plt.figure(k,figsize=(30,30))\n",
    "    i = 0\n",
    "    for f in h0_sr[k]:\n",
    "        if classification[i] ==2:\n",
    "            color = \"black\"\n",
    "        else:\n",
    "            color = \"red\"\n",
    "        f.plot(color = color)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = []\n",
    "i = 0\n",
    "points = []\n",
    "while i < len(h0_sr[\"10_25\"]):\n",
    "    x = h0_sr[\"0_15\"][i].lp_distance( h0_sr[\"10_25\"][i])\n",
    "    if x > 125:\n",
    "        w.append(i)\n",
    "    y = h0_sr[\"10_25\"][i].lp_distance( h0_sr[\"10_30\"][i])\n",
    "    points.append([x,y])\n",
    "    i += 1\n",
    "i = 0\n",
    "plt.figure(figsize=(20,20))\n",
    "while i < len(points):\n",
    "    if classification[i] ==2:\n",
    "        color = \"black\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    plt.scatter(points[i][0],points[i][1], color=color)\n",
    "    i += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in distributions.keys():\n",
    "    fig = plt.figure(k,figsize=(30,30))\n",
    "    i = 0\n",
    "    for f in h1_sr[k]:\n",
    "        if classification[i] ==2:\n",
    "            color = \"black\"\n",
    "            linewidth = 1\n",
    "        else:\n",
    "            color = \"red\"\n",
    "            linewidth=0.2\n",
    "        f.plot(color = color, linewidth=linewidth)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in w:\n",
    "    if classification[i]!=2:\n",
    "        a+= 1\n",
    "print(a)\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions[\"0_15\"] = sr.get_distribution(name=\"uniform\", interval=[0,15])\n",
    "distributions[\"5_20\"] = sr.get_distribution(name=\"uniform\", interval=[5,20])\n",
    "distributions[\"10_25\"] = sr.get_distribution(name=\"uniform\", interval=[10,25])\n",
    "distributions[\"10_30\"] = sr.get_distribution(name=\"uniform\", interval=[10,30])\n",
    "distributions[\"15_30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "for f in h0_sr[\"5_20\"]:\n",
    "    f.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "for f in h0_sr[\"10_27\"]:\n",
    "    f.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo SE Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
